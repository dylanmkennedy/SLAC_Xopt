{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "from custom_mean import CustomMean, LinearCalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307189e",
   "metadata": {},
   "source": [
    "# Ground Truth Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal(x):\n",
    "    \"\"\"\n",
    "    Simple sinusoidal function which can be used as ground truth.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): A tensor of shape (n_batch, n_samples, n_dim).\n",
    "    \"\"\"\n",
    "    y = torch.sin(2 * torch.pi * x)\n",
    "    return y\n",
    "\n",
    "\n",
    "def quadratic(x, max_pos=0.5, max_val=0.5):\n",
    "    \"\"\"\n",
    "    Simple quadratic function which can be used as ground truth.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): A tensor of shape (n_batch, n_samples, n_dim).\n",
    "        max_pos (float): The x-coordinate at the maximum.\n",
    "        max_val (float): The y-value at the maximum.\n",
    "    \"\"\"\n",
    "    return max_val - 20 * (x - max_pos) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d43e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the domain and plot ground truth functions\n",
    "x_lim = (0.0, 1.0)\n",
    "test_x = torch.linspace(*x_lim, 100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].plot(test_x, sinusoidal(test_x), \"C0-\")\n",
    "ax[0].set_title(\"sinusoidal\")\n",
    "ax[1].plot(test_x, quadratic(test_x), \"C0-\")\n",
    "ax[1].set_title(\"quadratic\")\n",
    "for i in range(2):\n",
    "    ax[i].set_xlim(x_lim)\n",
    "    ax[i].set_xlabel(\"x\")\n",
    "    ax[i].set_ylabel(\"f\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf5240",
   "metadata": {},
   "source": [
    "# Use Mismatched Ground Truth as Prior Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MismatchedGT(torch.nn.Module):\n",
    "    def __init__(self, ground_truth, **kwargs):\n",
    "        \"\"\"\n",
    "        Prediction of the ground truth function with optional linear mismatches in x and y.\n",
    "        \n",
    "        Args:\n",
    "            ground_truth (Callable): Ground truth function.\n",
    "        \n",
    "        Keyword Args:\n",
    "            x_dim (int): The input dimension. Defaults to 1.\n",
    "            x_shift (torch.Tensor): A tensor of shape (x_dim). Defaults to zeros.\n",
    "            x_scale (torch.Tensor): A tensor of shape (x_dim). Defaults to ones.\n",
    "            y_shift (torch.Tensor): A tensor of shape (1). Defaults to zero.\n",
    "            y_scale (torch.Tensor): A tensor of shape (1). Defaults to one.\n",
    "        \"\"\"\n",
    "        super(MismatchedGT, self).__init__()\n",
    "        self.ground_truth = ground_truth\n",
    "        assert callable(self.ground_truth), f\"Expected ground_truth to be callable\"\n",
    "        \n",
    "        # parameters for mismatch in x\n",
    "        x_dim = kwargs.get(\"x_dim\", 1)\n",
    "        x_shape = torch.Size([x_dim])\n",
    "        self.x_shift = kwargs.get(\"x_shift\", torch.zeros(x_shape))\n",
    "        assert self.x_shift.shape == x_shape, f\"Expected tensor with {x_shape}, but got: {self.x_shift.shape}\"\n",
    "        self.x_scale = kwargs.get(\"x_scale\", torch.ones(x_shape))\n",
    "        assert self.x_scale.shape == x_shape, f\"Expected tensor with {x_shape}, but got: {self.x_scale.shape}\"\n",
    "        \n",
    "        # parameters for mismatch in y\n",
    "        y_shape = torch.Size([1])\n",
    "        self.y_shift = kwargs.get(\"y_shift\", torch.zeros(y_shape))\n",
    "        assert self.y_shift.shape == y_shape, f\"Expected tensor with {y_shape}, but got: {self.y_shift.shape}\"\n",
    "        self.y_scale = kwargs.get(\"y_scale\", torch.ones(y_shape))\n",
    "        assert self.y_scale.shape == y_shape, f\"Expected tensor with {y_shape}, but got: {self.y_scale.shape}\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Expects tensor of shape (n_batch, n_samples, n_dim)\"\"\"\n",
    "        mismatched_x = self.x_scale * x + self.x_shift\n",
    "        y = self.y_scale * self.ground_truth(mismatched_x).squeeze(-1) + self.y_shift\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba798de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_gt = MismatchedGT(\n",
    "    ground_truth=sinusoidal, \n",
    "    x_shift=torch.tensor([0.1]),\n",
    "    x_scale=torch.tensor([1.1]),\n",
    "    y_shift=torch.tensor([0.15]),\n",
    "    y_scale=torch.tensor([1.05]),\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "ax.plot(test_x, mismatched_gt(test_x), \"C0-\", label=\"prior mean\")\n",
    "ax.plot(test_x, mismatched_gt.ground_truth(test_x), \"C3--\", label=\"ground truth\")\n",
    "ax.set_xlim(x_lim)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"f\")\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f77c19",
   "metadata": {},
   "source": [
    "# Definition of Custom Means with and without Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no additional learnable parameters\n",
    "cm = CustomMean(mismatched_gt, Normalize(1), Standardize(1))\n",
    "\n",
    "# learnable linear transformations\n",
    "pcm = LinearCalibration(\n",
    "    mismatched_gt, \n",
    "    Normalize(1, bounds=torch.FloatTensor(x_lim).double().reshape(2, 1)),\n",
    "    Standardize(1), \n",
    "    x_dim=1,\n",
    ")\n",
    "\n",
    "custom_means = [cm, pcm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d337321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gp(train_x, train_y, mean_module):\n",
    "    gp = SingleTaskGP(\n",
    "        train_x, \n",
    "        train_y,\n",
    "        mean_module=mean_module,\n",
    "        input_transform=mean_module.input_transformer,\n",
    "        outcome_transform=mean_module.outcome_transformer,\n",
    "    )\n",
    "    gp.likelihood.noise = torch.tensor(1e-4)\n",
    "    gp.likelihood.noise.requires_grad = False\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f961338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of steps for BO\n",
    "n_steps = 5\n",
    "\n",
    "# create plotting axes\n",
    "fig,ax = plt.subplots(2, n_steps, sharex=\"all\", sharey=\"all\")\n",
    "fig.set_size_inches(12, 5)\n",
    "\n",
    "# generate intial data\n",
    "train_x = torch.tensor([0.6]).repeat(2, 1).double()\n",
    "train_y = mismatched_gt.ground_truth(train_x)\n",
    "\n",
    "for i in range(n_steps):\n",
    "    # create GP models\n",
    "    gps = []\n",
    "    for j, custom_mean in enumerate(custom_means):\n",
    "        gp = create_gp(train_x[j].unsqueeze(-1), train_y[j].unsqueeze(-1), custom_mean)\n",
    "        gps.append(gp)\n",
    "    \n",
    "    # maximum likelihood fits\n",
    "    for gp in gps:\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        \n",
    "    candidates = []\n",
    "    for j, gp in enumerate(gps):\n",
    "        # create and optimize acquisition function using the GP\n",
    "        acq = ExpectedImprovement(gp, train_y[j].max())\n",
    "        candidate, _ = optimize_acqf(\n",
    "            acq_function=acq,\n",
    "            bounds=torch.tensor([0.0, 1.0]).reshape(2, 1),\n",
    "            q=1,\n",
    "            num_restarts=5,\n",
    "            raw_samples=20\n",
    "        )\n",
    "        candidates.append(candidate)\n",
    "        \n",
    "        # posterior and acquisition function\n",
    "        with torch.no_grad():\n",
    "            # get GP posterior\n",
    "            post = gp.posterior(test_x.unsqueeze(-1))\n",
    "\n",
    "            # get posterior means and confidence regions\n",
    "            mean = post.mean.flatten()\n",
    "            l, u = post.mvn.confidence_region()\n",
    "\n",
    "            # get acquisition function values\n",
    "            acq_val = acq(test_x.reshape(-1, 1, 1))\n",
    "\n",
    "        # plot GP model, data and ground truth\n",
    "        ax[j, i].plot(test_x, mean, label=\"posterior mean\")\n",
    "        ax[j, i].fill_between(test_x, l.squeeze(), u.squeeze(), alpha=0.25, label=\"confidence region\")\n",
    "        ax[j, i].plot(train_x[j], train_y[j], \"oC2\", zorder=10)\n",
    "        ax[j, i].plot(test_x, mismatched_gt.ground_truth(test_x), \"C3--\", zorder=1, label=\"ground truth\")\n",
    "        ax[j, i].set_xlim(x_lim)\n",
    "        ax[j, i].set_xticks([0.0, 0.5, 1.0])\n",
    "        if j == 0:\n",
    "            ax[j, i].set_title(f\"step {i+1}\")\n",
    "        if j == len(gps) - 1:\n",
    "            ax[j, i].set_xlabel(f\"x\")\n",
    "        \n",
    "        # plot the acquisition function\n",
    "        ax2 = ax[j, i].twinx()\n",
    "        ax2.plot(test_x, acq_val, \"C1\")\n",
    "        ax2.fill_between(test_x, torch.zeros_like(acq_val), acq_val, alpha=0.5, fc=\"C1\")\n",
    "        ax2.set_yticklabels([])\n",
    "        ax2.set_ylim(0, 10.0 * acq_val.max())\n",
    "\n",
    "        # plot the maximum point of the acquisition function\n",
    "        ax2.plot(test_x[torch.argmax(acq_val)], acq_val[torch.argmax(acq_val)] * 1.7,\n",
    "                 marker=\"v\", ms=10)\n",
    "        \n",
    "    # add maximization points and resulting observations to training data\n",
    "    train_x = torch.cat([train_x, torch.tensor(candidates).unsqueeze(-1)], dim=-1)\n",
    "    train_y = mismatched_gt.ground_truth(train_x)\n",
    "    \n",
    "for i in range(2):    \n",
    "    ax[i, 0].set_ylabel(\"f\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75be70c",
   "metadata": {},
   "source": [
    "# Learned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef836904",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(custom_mean, \"x_shift\"):\n",
    "    print(\"learned x_shift: {:.2f} ({:.2f})\".format(*(-custom_mean.x_shift), *mismatched_gt.x_shift))\n",
    "if hasattr(custom_mean, \"x_scale\"):\n",
    "    print(\"learned x_scale: {:.2f} ({:.2f})\".format(*(1 / custom_mean.x_scale), *mismatched_gt.x_scale))\n",
    "if hasattr(custom_mean, \"y_shift\"):\n",
    "    print(\"learned y_shift: {:.2f} ({:.2f})\".format(\n",
    "        *(-custom_mean.y_shift), *mismatched_gt.y_shift))\n",
    "if hasattr(custom_mean, \"y_scale\"):\n",
    "    print(\"learned y_scale: {:.2f} ({:.2f})\".format(\n",
    "        *(1 / custom_mean.y_scale), *mismatched_gt.y_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e1067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
