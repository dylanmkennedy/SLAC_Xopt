{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 2D Injector Optimization with NN Prior at LCLS\n",
    "Aiming to optimize transverse beam size in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "if hostname == \"lcls-srv04\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(1)\n",
    "elif hostname == \"test-rhel7\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:42:59.049600800Z",
     "start_time": "2023-08-17T02:42:59.040600400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# optionally add scripts location to path\n",
    "if True:\n",
    "    import sys\n",
    "    sys.path.append(\"../../\")\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "run_dir = \"/home/physics3/ml_tuning/20231120_LCLS_Injector/\"\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Set up image diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:43:02.093712200Z",
     "start_time": "2023-08-17T02:42:59.051600200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scripts.image import ImageDiagnostic\n",
    "import yaml\n",
    "\n",
    "fname = \"../OTR3_config.yml\"\n",
    "image_diagnostic = ImageDiagnostic.parse_obj(yaml.safe_load(open(fname)))\n",
    "image_diagnostic.save_image_location = run_dir\n",
    "image_diagnostic.n_fitting_restarts = 2\n",
    "image_diagnostic.visualize = False\n",
    "image_diagnostic.background_file = run_dir + \"OTRS_IN20_621_background.npy\"\n",
    "print(image_diagnostic.yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_diagnostic.measure_background(file_location=run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_diagnostic.background_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_diagnostic.background_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_diagnostic.test_measurement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xopt import VOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../variables.csv\"\n",
    "VARIABLE_RANGES = pd.read_csv(filename, index_col=0, header=None).T.to_dict(orient='list')\n",
    "\n",
    "IMAGE_CONSTRAINTS = {\n",
    "    \"bb_penalty\": [\"LESS_THAN\", 0.0],\n",
    "    \"log10_total_intensity\": [\"GREATER_THAN\", image_diagnostic.min_log_intensity]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES = [\"SOLN:IN20:121:BCTRL\", \"QUAD:IN20:121:BCTRL\"]\n",
    "\n",
    "vocs = VOCS(\n",
    "    variables = {ele: VARIABLE_RANGES[ele] for ele in VARIABLES},\n",
    "    constraints = IMAGE_CONSTRAINTS,\n",
    "    objectives = {\"total_size\": \"MINIMIZE\"},\n",
    ")\n",
    "print(vocs.as_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from epics import caput, caget_many, caget\n",
    "\n",
    "from utils import get_model_predictions, numpy_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_scale = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_beamsize(input_dict, generator = None):\n",
    "    global image_diagnostic\n",
    "    # set PVs\n",
    "    for k, v in input_dict.items():\n",
    "        print(f'CAPUT {k} {v}')\n",
    "        caput(k, v)\n",
    "\n",
    "    sleep(5.0)\n",
    "\n",
    "    # get beam sizes from image diagnostic\n",
    "    metadata = input_dict\n",
    "    results = image_diagnostic.measure_beamsize(1, **metadata)\n",
    "    results[\"S_x_mm\"] = np.array(results[\"Sx\"]) * 1e-3\n",
    "    results[\"S_y_mm\"] = np.array(results[\"Sy\"]) * 1e-3\n",
    "\n",
    "    # get other PV's NOTE: Measurements not synchronous with beamsize measurements!\n",
    "    results = results\n",
    "\n",
    "    # add total beam size\n",
    "    sigma_xy = np.sqrt(np.array(results[\"Sx\"]) ** 2 + np.array(results[\"Sy\"]) ** 2)\n",
    "    roundness = np.abs(np.array(results[\"Sx\"]) - np.array(results[\"Sy\"]))\n",
    "    results[\"sigma_xy\"] = sigma_xy\n",
    "    results[\"total_size\"] = objective_scale * (sigma_xy + roundness)    \n",
    "    # results[\"total_size\"] = np.sqrt(np.abs(np.array(results[\"Sx\"])) * np.array(results[\"Sy\"]))\n",
    "    \n",
    "    # GP model predictions\n",
    "    model_predictions = get_model_predictions(input_dict, generator)\n",
    "    results.update(model_predictions)\n",
    "\n",
    "    numpy_save()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NN prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lume_model.utils import variables_from_yaml\n",
    "from lume_model.models import TorchModel, TorchModule\n",
    "\n",
    "sys.path.append(\"calibration/calibration_modules/\")\n",
    "from decoupled_linear import OutputOffset, OutputScale, DecoupledLinearOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lcls_cu_injector_nn_model/\"\n",
    "\n",
    "# # load nn_to_cal transformers\n",
    "# reg = \"low\"  # \"low\" or \"high\"\n",
    "# input_nn_to_cal = torch.load(f\"calibration/input_nn_to_cal_{reg}_reg.pt\")\n",
    "# output_nn_to_cal = torch.load(f\"calibration/output_nn_to_cal_{reg}_reg.pt\")\n",
    "\n",
    "# load sim_to_nn transformers\n",
    "input_sim_to_nn = torch.load(model_path + \"model/input_sim_to_nn.pt\")\n",
    "output_sim_to_nn = torch.load(model_path + \"model/output_sim_to_nn.pt\")\n",
    "\n",
    "# load pv_to_sim transformers\n",
    "input_pv_to_sim = torch.load(model_path + \"model/input_pv_to_sim.pt\")\n",
    "output_pv_to_sim = torch.load(model_path + \"model/output_pv_to_sim.pt\")\n",
    "\n",
    "# load in- and output variable specification\n",
    "input_variables, output_variables = variables_from_yaml(model_path + \"model/pv_variables.yml\")\n",
    "# input_variables, output_variables = variables_from_yaml(f\"calibration/pv_variables_{reg}_reg_pydantic2.yml\")\n",
    "\n",
    "# replace keys in input variables\n",
    "for var in input_variables:\n",
    "    var.name = var.name.replace(\"BACT\", \"BCTRL\")\n",
    "\n",
    "# create TorchModel\n",
    "lume_model = TorchModel(\n",
    "    model=model_path + \"model/model.pt\",\n",
    "    input_variables=input_variables,\n",
    "    output_variables=output_variables,\n",
    "    input_transformers=[input_pv_to_sim, input_sim_to_nn],\n",
    "    output_transformers=[output_sim_to_nn, output_pv_to_sim],\n",
    "    # input_transformers=[input_pv_to_sim, input_sim_to_nn, input_nn_to_cal],\n",
    "    # output_transformers=[output_nn_to_cal, output_sim_to_nn, output_pv_to_sim],\n",
    ")\n",
    "\n",
    "# wrap in TorchModule\n",
    "lume_module = TorchModule(\n",
    "    model=lume_model,\n",
    "    input_order=vocs.variable_names,\n",
    "    output_order=lume_model.output_names[0:2],\n",
    ")\n",
    "\n",
    "# define objective model\n",
    "class ObjectiveModel(torch.nn.Module):\n",
    "    def __init__(self, model: TorchModule):\n",
    "        super(ObjectiveModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @staticmethod\n",
    "    def function(sigma_x: torch.Tensor, sigma_y: torch.Tensor) -> torch.Tensor:\n",
    "        # using this calculation due to occasional negative values\n",
    "        sigma_xy = torch.sqrt(sigma_x ** 2 + sigma_y ** 2)\n",
    "        roundness = torch.abs(sigma_x - sigma_y)\n",
    "        return (sigma_xy + roundness) * objective_scale\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        idx_sigma_x = self.model.output_order.index(\"OTRS:IN20:571:XRMS\")\n",
    "        idx_sigma_y = self.model.output_order.index(\"OTRS:IN20:571:YRMS\")\n",
    "        sigma_x = self.model(x)[..., idx_sigma_x]\n",
    "        sigma_y = self.model(x)[..., idx_sigma_y]\n",
    "        return self.function(sigma_x, sigma_y)\n",
    "\n",
    "\n",
    "objective_model = ObjectiveModel(lume_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom mean\n",
    "objective_model.requires_grad_(False);\n",
    "\n",
    "custom_mean = objective_model\n",
    "# custom_mean = OutputOffset(\n",
    "#     model=objective_model,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restrict ranges based on profile monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocs.variables = {k: input_variables[lume_model.input_names.index(k)].value_range for k in vocs.variable_names}\n",
    "vocs.variables[\"SOLN:IN20:121:BCTRL\"] = [0.467, 0.479]\n",
    "print(vocs.as_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Xopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:43:02.453721600Z",
     "start_time": "2023-08-17T02:43:02.097709300Z"
    }
   },
   "outputs": [],
   "source": [
    "from xopt import Xopt, VOCS\n",
    "from xopt.evaluator import Evaluator\n",
    "from xopt.numerical_optimizer import LBFGSOptimizer\n",
    "from xopt.generators.bayesian import ExpectedImprovementGenerator\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor\n",
    "\n",
    "# remember to set use low noise prior to false!!!\n",
    "gp_constructor = StandardModelConstructor(\n",
    "    use_low_noise_prior=False,\n",
    "    mean_modules={\"total_size\": custom_mean},\n",
    "    trainable_mean_keys=[\"total_size\"],\n",
    ")\n",
    "generator = ExpectedImprovementGenerator(\n",
    "    vocs=vocs,\n",
    "    gp_constructor=gp_constructor,\n",
    ")\n",
    "generator.numerical_optimizer.max_iter = 200\n",
    "evaluator = Evaluator(function=eval_beamsize, function_kwargs={\"generator\": generator})\n",
    "X = Xopt(generator=generator, evaluator=evaluator, vocs=vocs)\n",
    "X.evaluator = Evaluator(function=eval_beamsize, function_kwargs={\"generator\": X.generator})\n",
    "X.dump_file = run_dir + \"nn_optimization_2d_1.yml\"\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_init = 3\n",
    "initial_data_file = os.path.join(run_dir, f\"optimization_2d_initial_data_n={n_init}.csv\")\n",
    "\n",
    "if os.path.isfile(initial_data_file):\n",
    "    initial_data = pd.read_csv(initial_data_file)\n",
    "    X.add_data(initial_data)\n",
    "else:\n",
    "    X.random_evaluate(n_init)\n",
    "    X.data.to_csv(initial_data_file, index=False)\n",
    "\n",
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    X.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.data.plot(y=\"total_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.data.plot(y=X.vocs.variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.generator.computation_time[[\"training\", \"acquisition_optimization\"]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running minimum\n",
    "running_min = []\n",
    "for i in range(len(X.data)):\n",
    "    running_min.append(X.data[vocs.objective_names[0]].iloc[:i+1].min())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(X.data.index.values, X.data[vocs.objective_names[0]].values, label=\"BO Sequence\")\n",
    "ax.plot(X.data.index.values, running_min, label=\"Running Minimum\")\n",
    "ax.set_ylabel(f\"{vocs.objective_names[0]}\")\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display GP model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.data[[\"total_size\" + k for k in [\"\", \"_prior_mean\", \"_posterior_mean\", \"_posterior_sd\"]]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.generator.visualize_model(show_prior_mean=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nnprior]",
   "language": "python",
   "name": "conda-env-nnprior-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
