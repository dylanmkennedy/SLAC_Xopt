{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = socket.gethostname()\n",
    "if hostname == \"lcls-srv04\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(1)\n",
    "elif hostname == \"test-rhel7\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:42:59.049600800Z",
     "start_time": "2023-08-17T02:42:59.040600400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# optionally add scripts location to path\n",
    "if True:\n",
    "    import sys\n",
    "    sys.path.append(\"../../\")\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "run_dir = \"/home/physics3/ml_tuning/20231120_LCLS_Injector/\"\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Set up image diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from scripts.image import ImageDiagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:43:02.093712200Z",
     "start_time": "2023-08-17T02:42:59.051600200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fname = \"../OTR3_config.yml\"\n",
    "image_diagnostic = ImageDiagnostic.parse_obj(yaml.safe_load(open(fname)))\n",
    "image_diagnostic.save_image_location = run_dir\n",
    "image_diagnostic.n_fitting_restarts = 2\n",
    "image_diagnostic.visualize = False\n",
    "image_diagnostic.background_file = run_dir + \"OTRS_IN20_621_background.npy\"\n",
    "print(image_diagnostic.yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_diagnostic.measure_background(file_location=run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_diagnostic.background_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_diagnostic.background_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_diagnostic.test_measurement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xopt import VOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"SOLN:IN20:121:BCTRL\", \"QUAD:IN20:121:BCTRL\"]\n",
    "# variables = [\n",
    "#     \"SOLN:IN20:121:BCTRL\", \"QUAD:IN20:121:BCTRL\", \"QUAD:IN20:122:BCTRL\",\n",
    "#     \"QUAD:IN20:361:BCTRL\", \"QUAD:IN20:371:BCTRL\", \"QUAD:IN20:425:BCTRL\",\n",
    "#     \"QUAD:IN20:441:BCTRL\", \"QUAD:IN20:511:BCTRL\", \"QUAD:IN20:525:BCTRL\",\n",
    "# ]\n",
    "\n",
    "img_constraints = {\n",
    "    \"bb_penalty\": [\"LESS_THAN\", 0.0],\n",
    "    \"log10_total_intensity\": [\"GREATER_THAN\", image_diagnostic.min_log_intensity]\n",
    "}\n",
    "\n",
    "filename = \"../variables.csv\"\n",
    "variable_ranges = pd.read_csv(filename, index_col=0, header=None).T.to_dict(orient='list')\n",
    "vocs = VOCS(\n",
    "    variables = {ele: variable_ranges[ele] for ele in variables},\n",
    "    objectives = {\"total_size\": \"MINIMIZE\"},\n",
    "    constraints = img_constraints,\n",
    ")\n",
    "print(vocs.as_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NN prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"calibration/calibration_modules/\")\n",
    "from decoupled_linear import OutputOffset, DecoupledLinearOutput\n",
    "from utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_model = load_model(\n",
    "    input_variables=vocs.variable_names,\n",
    "    model_path=\"lcls_cu_injector_nn_model/\",\n",
    ")\n",
    "lume_model = objective_model.model.model\n",
    "\n",
    "# define miscalibrated objective model\n",
    "y_size = len(vocs.objective_names)\n",
    "miscal_model = DecoupledLinearOutput(\n",
    "    model=objective_model,\n",
    "    y_offset_initial=torch.full((y_size,), -0.5),\n",
    "    y_scale_initial=torch.ones(y_size),\n",
    ")\n",
    "miscal_model.requires_grad_(False);\n",
    "\n",
    "# define prior mean\n",
    "prior_mean = OutputOffset(\n",
    "    model=miscal_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from time import sleep\n",
    "from epics import caput, caget_many, caget\n",
    "from utils import get_model_predictions, numpy_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_dict, generator = None):\n",
    "    global image_diagnostic\n",
    "    # set PVs\n",
    "    for k, v in input_dict.items():\n",
    "        print(f'CAPUT {k} {v}')\n",
    "        caput(k, v)\n",
    "\n",
    "    sleep(5.0)\n",
    "\n",
    "    # get beam sizes from image diagnostic\n",
    "    metadata = input_dict\n",
    "    results = image_diagnostic.measure_beamsize(1, **metadata)\n",
    "    results[\"S_x_mm\"] = np.array(results[\"Sx\"]) * 1e-3\n",
    "    results[\"S_y_mm\"] = np.array(results[\"Sy\"]) * 1e-3\n",
    "\n",
    "    # get other PV's NOTE: Measurements not synchronous with beamsize measurements!\n",
    "    results = results\n",
    "\n",
    "    # add total beam size\n",
    "    sigma_xy = np.sqrt(np.array(results[\"Sx\"]) ** 2 + np.array(results[\"Sy\"]) ** 2)\n",
    "    roundness = np.abs(np.array(results[\"Sx\"]) - np.array(results[\"Sy\"]))\n",
    "    results[\"sigma_xy\"] = sigma_xy\n",
    "    results[\"total_size\"] = objective_model.objective_scale * (sigma_xy + roundness)\n",
    "    # results[\"total_size\"] = np.sqrt(np.abs(np.array(results[\"Sx\"])) * np.array(results[\"Sy\"]))\n",
    "    \n",
    "    # GP model predictions\n",
    "    model_predictions = get_model_predictions(input_dict, generator)\n",
    "    results.update(model_predictions)\n",
    "\n",
    "    numpy_save()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom mean\n",
    "objective_model.requires_grad_(False);\n",
    "\n",
    "custom_mean = objective_model\n",
    "# custom_mean = OutputOffset(\n",
    "#     model=objective_model,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust variable ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocs.variables = {\n",
    "    k: lume_model.input_variables[lume_model.input_names.index(k)].value_range \n",
    "    for k in vocs.variable_names\n",
    "}\n",
    "vocs.variables[\"SOLN:IN20:121:BCTRL\"] = [0.467, 0.479]\n",
    "print(vocs.as_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xopt.utils import get_local_region\n",
    "\n",
    "# # get current point\n",
    "# current_value = {\n",
    "#     'SOLN:IN20:121:BCTRL': 0.4809822,\n",
    "#     'QUAD:IN20:121:BCTRL': 0.0018092622,\n",
    "#     'QUAD:IN20:122:BCTRL': -0.0110517,\n",
    "#     'QUAD:IN20:361:BCTRL': -3.37538,\n",
    "#     'QUAD:IN20:371:BCTRL': 2.55894,\n",
    "#     'QUAD:IN20:425:BCTRL': -1.11579,\n",
    "#     'QUAD:IN20:441:BCTRL': -0.11462,\n",
    "#     'QUAD:IN20:511:BCTRL': 3.4887333,\n",
    "#     'QUAD:IN20:525:BCTRL': -2.887897,\n",
    "# }\n",
    "\n",
    "# # get small region around current point to sample\n",
    "# random_sample_region = get_local_region(current_value, vocs, fraction=0.4)\n",
    "# random_sample_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clamped_vars = {}\n",
    "# for k, v in random_sample_region.items():\n",
    "#     clamped_vars[k] = [\n",
    "#         np.max([random_sample_region[k][0], vocs.variables[k][0]]),\n",
    "#         np.min([random_sample_region[k][1], vocs.variables[k][1]]),\n",
    "#     ]\n",
    "# vocs.variables = clamped_vars\n",
    "# print(vocs.as_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Xopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt import Xopt, VOCS\n",
    "from xopt.evaluator import Evaluator\n",
    "from xopt.numerical_optimizer import LBFGSOptimizer\n",
    "from xopt.generators.bayesian import ExpectedImprovementGenerator\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to set use low noise prior to false!!!\n",
    "gp_constructor = StandardModelConstructor(\n",
    "    use_low_noise_prior=False,\n",
    "    mean_modules={vocs.objective_names[0]: prior_mean},\n",
    "    trainable_mean_keys=[vocs.objective_names[0]],\n",
    ")\n",
    "generator = ExpectedImprovementGenerator(\n",
    "    vocs=vocs,\n",
    "    gp_constructor=gp_constructor,\n",
    ")\n",
    "generator.numerical_optimizer.max_iter = 200\n",
    "evaluator = Evaluator(function=evaluate, function_kwargs={\"generator\": None})\n",
    "X = Xopt(generator=generator, evaluator=evaluator, vocs=vocs)\n",
    "\n",
    "# pass generator to evaluator to compute model predictions\n",
    "X.evaluator = Evaluator(function=evaluate, function_kwargs={\"generator\": X.generator})\n",
    "\n",
    "# define dump file\n",
    "dump_file = run_dir + \"optimize_1.yml\"\n",
    "if os.path.isfile(dump_file):\n",
    "    print(\"Dump file exists already!\")\n",
    "X.dump_file = dump_file\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_init = 10\n",
    "initial_data_file = os.path.join(run_dir, f\"optimize_initial_data_n={n_init}.csv\")\n",
    "\n",
    "if os.path.isfile(initial_data_file):\n",
    "    initial_data = pd.read_csv(initial_data_file)\n",
    "    X.add_data(initial_data)\n",
    "else:\n",
    "    X.random_evaluate(n_init)\n",
    "    X.data.to_csv(initial_data_file, index=False)\n",
    "\n",
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    X.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_running_optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = get_running_optimum(\n",
    "    data=X.data,\n",
    "    objective_name=X.vocs.objective_names[0],\n",
    "    maximize=X.vocs.objectives[X.vocs.objective_names[0]].upper() == \"MAXIMIZE\",\n",
    ")\n",
    "ax = X.data.plot(y=X.vocs.objective_names[0])\n",
    "ax.plot(opt, label=\"running_optimum\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocs.normalize_inputs(X.data).plot(y=X.vocs.variable_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.generator.computation_time[[\"training\", \"acquisition_optimization\"]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_suffixes = [\"\", \"_prior_mean\", \"_posterior_mean\", \"_posterior_sd\"]\n",
    "X.data[[X.vocs.objective_names[0] + k for k in label_suffixes]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = X.vocs.variable_names\n",
    "if X.vocs.n_variables not in [1, 2]:\n",
    "    variable_names = [\"SOLN:IN20:121:BCTRL\"]\n",
    "\n",
    "X.generator.visualize_model(\n",
    "    variable_names=variable_names,\n",
    "    show_prior_mean=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nnprior]",
   "language": "python",
   "name": "conda-env-nnprior-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
